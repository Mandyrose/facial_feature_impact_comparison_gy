[DATASET]
filters = ["phase_perc_size"]
image_size = 224
net_input_size = 224
dataset_means = [0.4692, 0.4675, 0.3951]
dataset_stds = [0.2380, 0.2319, 0.2534]
# following parameter is the name of the important transforms
# the required parameters for the transforms should be accessed in the transforms_config.py file
transforms_type=birds
# set this dir to the dataset dir
raw_dataset_path = /home/KAD/project/datasets/260_birds_consolidated
crop_scale={"max": 1.0, "min": 1.0}
processed_dataset_root = /home/ssd_storage/datasets/processed/
class_filter_dataset_dir = phase_perc_size
# following parameter is a name for the created directory
dataset_name = individual_birds
phase_size_dict = {"train":0.8, "val": 0.15, "test":0.05}

[MODELLING]
feature_parallelized_architectures = ["VGG", "vgg11", "vgg11_bn", "vgg13", "vgg13_bn", "vgg16", "vgg16_bn",
    "vgg19_bn", "vgg19", "AlexNet", "alexnet"]
architecture = vgg16
# If you want to start from the middle of training, set this to the epoch you wish to start from (it will load start_epoch-1 from the dir)
start_epoch = 0
end_epoch = 100
num_batches_per_epoch_limit=1000
batch_size=128
is_pretrained = False
# NOAM: following parameter should be the same number of trained classes
num_classes = 500
criterion_name = CrossEntropyLoss
criterion_params = {}
workers=4
performance_test=LFW_TEST
#performance_test=None
perf_threshold=1.0
#each #num_epochs_to_test we make a LFW test
num_epochs_to_test=10

# NOAM: if starting from a pretrained model (like when finetuning) - the weights will be loaded from the given path:
# NOAM: when starting from pretrained model make sure the num_classes parameter is the same number of classes as in the
# weights in the file
# checkpoint_path=/home/administrator/experiments/all_ids/500_ids/500_ids_300_img_per_id_val_50/vgg16/models/120.pth


[OPTIMIZING]
# NOAM: Same class name as in torch.optim
optimizer = SGD
# NOAM: Same parameters as in the object constructor:
optimizer_params = {
    "lr": 0.01,
    "momentum": 0.9,
    "weight_decay": 5e-4}
# NOAM: Same class name as in torch.optim.lr_scheduler
lr_scheduler = StepLR
# NOAM: Same parameters as in the object constructor:
lr_scheduler_params = {
    "step_size": 10,
    "gamma": 0.1}

# FINETUNING section is only relevant when finetuning:
# [FINETUNING]
# classes_mode=replace
# #replace/append/skip
# num_classes=260
# #NOAM: The freeze_end parameter is the index of the layer we want to start training from,
# #i.e. if vgg16 is made of 42 consecutive torch.nn.Module objects (you can iterate a torch.nn.Module object's module() function)
# #then layer 40 is fc7
# #example: following code should print "(40, torch.nn.Linear(in_dim=4096, out_dim=4096))"
# #vgg16 = torchvision.models.vgg16()
# #for i, layer in iterate(vgg16.modules())
# #    print(i, type(layer))
# #
# freeze_end=35
# #42-fc8, 40-fc7, 35-fc6, 26-conv5, 19-conv4, 12-conv3, 7-conv2, 0-conv1

[GENERAL]
root_dir = /home/ssd_storage/experiments/students/Noam
#change to name of experiment (the output folder will be created accordingly)
# NOAM: change experiment name to a meaningful name
experiment_name = individual_birds_scratch_training

[LFW_TEST]
reps_layers=BlauchEquivalentExtractor
# NOAM: space-delimited pairs of images relative path to compare, with binary value stating 1-same, 0-diff
labeled_pairs_path=./lfw_test_pairs.txt
reps_cache_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/lfw/reps/
reps_results_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/${MODELLING:architecture}/results/
# NOAM: filename to save verification results (layer_depth, best_performance, best_threshold)
output_filename=lfw_results
# NOAM: which distance metric to use for verification (cos / l2)
comparison_metric=cos
# NOAM: parent directory completing the relative paths from labeled_pairs_path file, to a full path
lfw_dir=/home/administrator/datasets/lfw-align-128

[REP_BEHAVIOUR]
reps_layers=BlauchEquivalentExtractor
# NOAM: txt files with pairs of space-delimited relative filenames
pairs_paths = {
                "diff_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/diff_pairs.txt",
                "high_ps_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/high_ps_pairs.txt",
                "low_ps_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/low_ps_pairs.txt",
                "same_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/same_pairs.txt",
                "frontal-ref": "/home/administrator/datasets/faces_in_views/frontal_ref.txt",
                "frontal-quarter_left": "/home/administrator/datasets/faces_in_views/frontal_quarter_left.txt",
                "frontal-half_left": "/home/administrator/datasets/faces_in_views/frontal_half_left.txt",
                "half_left-half_right": "/home/administrator/datasets/faces_in_views/half_left-half_right.txt",
                "quarter_left-quarter_right": "/home/administrator/datasets/faces_in_views/quarter_left-quarter_right.txt"}
# NOAM: directory to the relative paths stated in the corresponding txt file
pairs_image_dirs = {
                    "diff_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
                    "high_ps_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
                    "low_ps_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
                    "same_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
                    "frontal-ref": "/home/administrator/datasets/faces_in_views",
                    "frontal-quarter_left": "/home/administrator/datasets/faces_in_views",
                    "frontal-half_left": "/home/administrator/datasets/faces_in_views",
                    "half_left-half_right": "/home/administrator/datasets/faces_in_views",
                    "quarter_left-quarter_right": "/home/administrator/datasets/faces_in_views"}

reps_cache_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/pairs/reps/
reps_results_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/${MODELLING:architecture}/results/
# NOAM: distance metric to use (cos/l2)
comparison_metric=l2

output_filename=reps

# TODO: Create a standard output folder and format
